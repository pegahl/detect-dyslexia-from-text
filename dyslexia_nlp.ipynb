{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pegahl/detect-dyslexia-from-text/blob/main/dyslexia_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kevIJOyRZnY0",
        "outputId": "4967a6f2-7a57-4f4d-8f32-686e79677f8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ],
      "source": [
        "pip install fuzzywuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DevBeHkz_dTX",
        "outputId": "a1c86abe-0f0d-4c15-adfe-7f889f23dc12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting phonetics\n",
            "  Downloading phonetics-1.0.5.tar.gz (8.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: phonetics\n",
            "  Building wheel for phonetics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for phonetics: filename=phonetics-1.0.5-py2.py3-none-any.whl size=8695 sha256=ac52968722e0ca43b9efde6915a587a687d4e630c72db82a5854bdb0710415cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/1e/82/80a78c7d1ad7fc6e0af1b4d9009360b251c0e50fe59f046edb\n",
            "Successfully built phonetics\n",
            "Installing collected packages: phonetics\n",
            "Successfully installed phonetics-1.0.5\n"
          ]
        }
      ],
      "source": [
        "pip install phonetics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8buLJPgF_ZpW",
        "outputId": "b6d887ba-55df-4368-b287-46283b9b3530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting levenshtein\n",
            "  Downloading levenshtein-0.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from levenshtein)\n",
            "  Downloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading levenshtein-0.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, levenshtein\n",
            "Successfully installed levenshtein-0.26.0 rapidfuzz-3.10.0\n"
          ]
        }
      ],
      "source": [
        "pip install levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD7_EGPjVips",
        "outputId": "ecc44c26-2e61-4ed4-d055-4f36e0524adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzy\n",
            "  Downloading Fuzzy-1.2.2.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fuzzy\n",
            "  Building wheel for fuzzy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fuzzy: filename=Fuzzy-1.2.2-cp310-cp310-linux_x86_64.whl size=206407 sha256=c03e7080e4d9e223cf296415437c411daf51b76dc181eaff0dc2b3691760802b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/a7/03/cb9f418321ad60736caa7a86f0077f6ab74b669885c3e03cc1\n",
            "Successfully built fuzzy\n",
            "Installing collected packages: fuzzy\n",
            "Successfully installed fuzzy-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Phase zero:\n",
        "\n",
        "####I extracted some features from the list of common diagnostic errors of dyslexic children based on the needs of the project. from 15 common errors, I chose 6 errors.\n",
        "---\n",
        "Categorized list of the common types of errors:\n",
        "1. Phonetic Spelling\n",
        "2. Homophone Confusion\n",
        "3. Letter Transposition\n",
        "4. Letter Omission\n",
        "5. Punctuation Omission\n",
        "6. Phonetic Substitution\n",
        "7. Grapheme-Phoneme Confusion\n",
        "8. Vowel Substitution\n",
        "9. Double Consonant Confusion\n",
        "10. Morphological Errors\n",
        "11. Visual Similarity Confusion\n",
        "12. Word Boundary Errors\n",
        "13. Dysgraphia-Related Errors (Handwriting Difficulties)\n",
        "14. Sequential Memory Issues\n",
        "15. Semantic Confusion\n",
        "---\n",
        "Six common and important types of language errors:\n",
        "1. Letter Omission\n",
        "2. Letter Transposition\n",
        "3. Homophone Confusion\n",
        "4. Vowel Substitution\n",
        "5. Extract Punctuation Omission\n",
        "6. Grapheme-Phoneme Confusion\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wAznyyUjNtFG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OsSI-CUGfFg",
        "outputId": "30c95c55-60ba-4463-92fa-c12b9610940d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')\n",
        "nltk.download('cmudict')\n",
        "import re\n",
        "import difflib\n",
        "from nltk.corpus import words\n",
        "from nltk.corpus import cmudict\n",
        "from nltk.util import ngrams\n",
        "from collections import defaultdict\n",
        "from Levenshtein import distance as levenshtein_distance\n",
        "from nltk.tokenize import word_tokenize\n",
        "import phonetics\n",
        "from fuzzywuzzy import process\n",
        "from itertools import permutations\n",
        "import string\n",
        "import fuzzy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the words corpus if not already downloaded\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBDNIOyPCKGJ",
        "outputId": "5b07175c-b9d4-4719-c295-1267aa7a39ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of correct words in English\n",
        "correct_words = set([word for word in words.words() if word.isalpha() and len(word) > 1])\n",
        "word_list = set(words.words())"
      ],
      "metadata": {
        "id": "vla2IXnbdN0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b068TnkViZNK"
      },
      "source": [
        "### ok but not perfect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y4BujLipxkv",
        "outputId": "bdbcdede-54e9-4bb1-8365-b1507f37e38b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spelling Errors Detected:\n"
          ]
        }
      ],
      "source": [
        "def detect_spelling_errors(text, threshold=80):\n",
        "    # Tokenize the input text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    spelling_errors = {}\n",
        "\n",
        "    for token in tokens:\n",
        "        lower_token = token.lower()\n",
        "\n",
        "        # Skip non-alphabetic tokens and very short tokens\n",
        "        if not lower_token.isalpha() or len(lower_token) < 2:\n",
        "            continue\n",
        "\n",
        "        # Find the closest match using Levenshtein Distance\n",
        "        best_match = process.extractOne(lower_token, correct_words)\n",
        "\n",
        "        # If similarity score is below the threshold, we consider it an error\n",
        "        if best_match and best_match[1] < threshold:\n",
        "            spelling_errors[token] = best_match[0]\n",
        "\n",
        "    return spelling_errors\n",
        "\n",
        "# Example text from the child\n",
        "text = \"\"\"Tim was playng in his yard wen he herd a nosie. It was a littel puppy!\n",
        "The puppy was hideing and didnt have a coller. Tim thot the puppy was lost so he toke him home.\n",
        "He calld the puppy Max. Tim’s parnts sed they had to find the ower so they went to the animel sheltur but no one knew the puppy.\"\"\"\n",
        "\n",
        "# Detect spelling errors\n",
        "spelling_errors = detect_spelling_errors(text, threshold=85)\n",
        "print(\"Spelling Errors Detected:\")\n",
        "for error, suggestion in spelling_errors.items():\n",
        "    print(f\"{error} -> {suggestion}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PErEDiRjQOAP"
      },
      "outputs": [],
      "source": [
        "#extra stuff\n",
        "def phonetic_similarity(word1, word2):\n",
        "    phonemes1 = set(ngrams(word1, 2))\n",
        "    phonemes2 = set(ngrams(word2, 2))\n",
        "\n",
        "    intersection = phonemes1.intersection(phonemes2)\n",
        "    union = phonemes1.union(phonemes2)\n",
        "\n",
        "    return len(intersection) / len(union)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RBPcq-iUQfs"
      },
      "outputs": [],
      "source": [
        "# import nltk\n",
        "# from nltk.corpus import cmudict\n",
        "# from collections import defaultdict\n",
        "\n",
        "# # Download required NLTK data\n",
        "# nltk.download('cmudict')\n",
        "# nltk.download('punkt')\n",
        "\n",
        "# def load_phonemes():\n",
        "#     d = cmudict.dict()\n",
        "#     return {word.lower(): [tuple(p[0] for p in pron) for pron in d[word.lower()]][:5]}\n",
        "\n",
        "# def phonetic_mismatch(word):\n",
        "#     phonemes = load_phonemes()[word.lower()]\n",
        "#     known_words = set(word.lower() for word in load_phonemes().keys())\n",
        "\n",
        "#     # Check if the word exists in the dictionary\n",
        "#     if word.lower() not in known_words:\n",
        "#         return True\n",
        "\n",
        "#     # Check if the phoneme representation matches the word\n",
        "#     if len(phonemes) == 0:\n",
        "#         return True\n",
        "\n",
        "#     # Check for unexpected phonemes\n",
        "#     unexpected_phones = set(phonemes).difference(set(load_phonemes().values()))\n",
        "#     if unexpected_phones:\n",
        "#         return True\n",
        "\n",
        "#     return False\n",
        "\n",
        "# def detect_phonetic_spelling(text, threshold=0.7):\n",
        "#     phonemes = load_phonemes()\n",
        "#     words = nltk.word_tokenize(text.lower())\n",
        "#     mismatches = []\n",
        "\n",
        "#     for i, word in enumerate(words):\n",
        "#         if phonetic_mismatch(word):\n",
        "#             mismatches.append((i, word))\n",
        "\n",
        "#     return mismatches\n",
        "\n",
        "# # Example usage\n",
        "# text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "# mismatches = detect_phonetic_spelling(text)\n",
        "\n",
        "# for index, word in mismatches:\n",
        "#     print(f\"Possible phonetic spelling issue: '{word}' at position {index}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdGaKc4UMO4x",
        "outputId": "d8b0523d-1ccb-4db8-ef59-a24dde397b0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['At',\n",
              " 'eight',\n",
              " \"o'clock\",\n",
              " 'on',\n",
              " 'Thursday',\n",
              " 'morning',\n",
              " '...',\n",
              " 'Arthur',\n",
              " 'did',\n",
              " \"n't\",\n",
              " 'feel',\n",
              " 'very',\n",
              " 'good',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#simple exmple:\n",
        "sentence = \"\"\"At eight o'clock on Thursday morning\n",
        "... Arthur didn't feel very good.\"\"\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGvTkUlGQ5gG"
      },
      "outputs": [],
      "source": [
        "# Preload words dictionary for comparison\n",
        "nltk_words = set(words.words())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkfU7IvRIcm6"
      },
      "source": [
        "**Load Dyslexia Data**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sample text\n",
        "text=\"\"\"Tim was playng in his yard wen he herd a nosie. It was a littel puppy! The puppy was hideing and didnt have a coller.\n",
        "Tim thot the puppy was lost so he toke him home.\n",
        "He calld the puppy Max. Tim’s parnts sed they had to find the ower so they went to the animel sheltur but no one knew the puppy.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6fkNjnpDCbj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkKxP-cDIpll"
      },
      "source": [
        "**Load Normal data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXQVJNb7G6_K"
      },
      "source": [
        "#0. Extract Phonetic Spelling\n",
        "\n",
        "*  Description: Writing words as they sound phonetically, which often leads to incorrect spelling.\n",
        "*   Example: wut instead of what\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFORPhHBmnyh"
      },
      "source": [
        "## Finding best algorithm for Phonetic spelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEXv6aN3nITl"
      },
      "source": [
        "**1. Soundex Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xypczem3arhL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Get the list of correct words in English and filter out too short or non-alphabetic words\n",
        "# correct_words = set([word for word in words.words() if word.isalpha() and len(word) > 1])\n",
        "\n",
        "# # Create a dictionary of correct words with their Soundex codes\n",
        "# correct_words_phonetic = {word: phonetics.soundex(word) for word in correct_words}\n",
        "\n",
        "# def detect_phonetic_spelling(text):\n",
        "#     # Tokenize the input text\n",
        "#     tokens = word_tokenize(text)\n",
        "\n",
        "#     phonetic_errors = {}\n",
        "\n",
        "#     for token in tokens:\n",
        "#         lower_token = token.lower()\n",
        "\n",
        "#         # Skip non-alphabetic tokens and very short tokens\n",
        "#         if not lower_token.isalpha() or len(lower_token) < 2:\n",
        "#             continue\n",
        "\n",
        "#         token_soundex = phonetics.soundex(lower_token)\n",
        "\n",
        "#         # If the word is not in the correct words list, check phonetically similar words\n",
        "#         if lower_token not in correct_words:\n",
        "#             # Find words with matching Soundex codes\n",
        "#             similar_words = [word for word, soundex_code in correct_words_phonetic.items() if soundex_code == token_soundex]\n",
        "\n",
        "#             if similar_words:\n",
        "#                 phonetic_errors[token] = similar_words[0]  # Choose the first match\n",
        "\n",
        "#     return phonetic_errors\n",
        "\n",
        "# # Example text from the child\n",
        "# text1 = \"\"\"Tim was playng in his yard wen he herd a nosie. It was a littel puppy!\n",
        "# The puppy was hideing and didnt have a coller. Tim thot the puppy was lost so he toke him home.\n",
        "# He calld the puppy Max. Tim’s parnts sed they had to find the ower so they went to the animel sheltur but no one knew the puppy.\"\"\"\n",
        "\n",
        "# # Detect phonetic spelling errors\n",
        "# phonetic_errors = detect_phonetic_spelling(text)\n",
        "# print(\"Phonetic Spelling Errors Detected:\")\n",
        "# for error, suggestion in phonetic_errors.items():\n",
        "#     print(f\"{error} -> {suggestion}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6b8Ma90nPzH"
      },
      "source": [
        "**2. Levenshtein Distance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckrzoIdsZKCj"
      },
      "outputs": [],
      "source": [
        "# # Function to detect Phonetic Spelling Errors (Levenshtein Distance)\n",
        "# def detect_phonetic_spelling(word, dictionary=nltk_words, threshold=2):\n",
        "#     closest_words = difflib.get_close_matches(word, dictionary, n=3)\n",
        "#     for correct_word in closest_words:\n",
        "#         if levenshtein_distance(word, correct_word) <= threshold:\n",
        "#             return f\"Phonetic spelling error: '{word}' is close to '{correct_word}'\"\n",
        "#     return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSwbJTNLnbdU"
      },
      "source": [
        "**3.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhS1pjI-E_UX"
      },
      "source": [
        "#1. Extract Letter Omission\n",
        "\n",
        "*  Description: Leaving out necessary letters within a word.\n",
        "\n",
        "*  Example: frend instead of friend\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have to ignore Letter Omission for this phase, cause we have a conflict between different errors. such as in our first sample text we detect \"thot\" as a letter omission but actually \"thot\" was \"that\" and we had Vowel Substitution! So I think that it's ok to ignore this error for now."
      ],
      "metadata": {
        "id": "ICB9jdV6MpOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text\n",
        "text = \"\"\"\n",
        "Tim was playng in his yard wen he herd a nosie. It was a littel puppy! The puppy was hideing and didnt have a coller.\n",
        "Tim thot the puppy was lost so he toke him home.\n",
        "He calld the puppy Max. Tim’s parnts sed they had to find the ower so they went to the animel sheltur but no one knew the puppy.\n",
        "\"\"\"\n",
        "#new code!\n",
        "def detect_letter_omission(word):\n",
        "  # A list of valid English words\n",
        "  word_list = set(words.words())\n",
        "\n",
        "  # Tokenize the text\n",
        "  tokens = nltk.word_tokenize(text.lower())\n",
        "\n",
        "  # Function to detect letter omission errors\n",
        "  def detect_omissions(word):\n",
        "      # Check if the word is in the dictionary\n",
        "      if word in word_list:\n",
        "          return None  # Word is correct, no need to check for omissions\n",
        "\n",
        "      alphabet = string.ascii_lowercase\n",
        "      candidates = set()\n",
        "\n",
        "      # Try adding a letter at each position in the word\n",
        "      for i in range(len(word) + 1):\n",
        "          for letter in alphabet:\n",
        "              candidate_word = word[:i] + letter + word[i:]\n",
        "              if candidate_word in word_list:\n",
        "                  candidates.add(candidate_word)\n",
        "\n",
        "      if candidates:\n",
        "          return candidates\n",
        "      else:\n",
        "          return None\n",
        "\n",
        "  # Check each word in the text for omissions\n",
        "  omission_errors = {}\n",
        "  for token in tokens:\n",
        "      omissions = detect_omissions(token)\n",
        "      if omissions:\n",
        "          omission_errors[token] = omissions\n",
        "\n",
        "  # Print the omission errors found\n",
        "  if omission_errors:\n",
        "      print(\"Omission Errors Found:\")\n",
        "      for original, corrections in omission_errors.items():\n",
        "          print(f\"'{original}' might have a letter omitted. Suggestions: {corrections}\")\n",
        "      print(\"\\n\")\n",
        "  else:\n",
        "      print(\"No omission errors found.\")\n",
        "  return None"
      ],
      "metadata": {
        "id": "8Q8MiT9LL0QM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detect_letter_omission(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4D0pgVRMYXE",
        "outputId": "578c9ae4-9843-44c1-f848-84394539eab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Omission Errors Found:\n",
            "'tim' might have a letter omitted. Suggestions: {'trim', 'time', 'stim'}\n",
            "'nosie' might have a letter omitted. Suggestions: {'nosine'}\n",
            "'hideing' might have a letter omitted. Suggestions: {'hideling'}\n",
            "'coller' might have a letter omitted. Suggestions: {'collier', 'choller', 'collery'}\n",
            "'thot' might have a letter omitted. Suggestions: {'thowt', 'thoft', 'thort'}\n",
            "'calld' might have a letter omitted. Suggestions: {'callid'}\n",
            "'max' might have a letter omitted. Suggestions: {'maux'}\n",
            "'sed' might have a letter omitted. Suggestions: {'seed', 'used', 'sned', 'sped', 'send', 'sled', 'shed'}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJw727duFAii"
      },
      "source": [
        "#2. Extract Letter Transposition\n",
        "\n",
        "*  Description: Reversing the order of letters in a word.\n",
        "* Example: gril instead of girl\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_letter_transpositions(word):\n",
        "  # Tokenize the text\n",
        "  tokens = nltk.word_tokenize(text.lower())\n",
        "\n",
        "  # Function to detect letter transpositions\n",
        "  def detect_transpositions(word):\n",
        "      # Check if word is in the dictionary\n",
        "      if word in word_list:\n",
        "          return None  # Word is correct, no need to check for transposition\n",
        "\n",
        "      # Generate all possible transpositions by swapping adjacent letters\n",
        "      transposed_candidates = set()\n",
        "      for i in range(len(word) - 1):\n",
        "          transposed_word = list(word)\n",
        "          # Swap adjacent letters\n",
        "          transposed_word[i], transposed_word[i + 1] = transposed_word[i + 1], transposed_word[i]\n",
        "          transposed_candidates.add(\"\".join(transposed_word))\n",
        "\n",
        "      # Check if any transposed candidates are valid words\n",
        "      valid_transpositions = [w for w in transposed_candidates if w in word_list]\n",
        "\n",
        "      if valid_transpositions:\n",
        "          return valid_transpositions\n",
        "      else:\n",
        "          return None\n",
        "\n",
        "  # Check each word in the text for transpositions\n",
        "  transposition_errors = {}\n",
        "  for token in tokens:\n",
        "      transpositions = detect_transpositions(token)\n",
        "      if transpositions:\n",
        "          transposition_errors[token] = transpositions\n",
        "\n",
        "  # Print the transposition errors found\n",
        "  if transposition_errors:\n",
        "      print(\"Transposition Errors Found:\")\n",
        "      for original, corrections in transposition_errors.items():\n",
        "        # .join(my_list)\n",
        "          print(f\"Letter transposition detected: '{original}' might be\",*corrections)\n",
        "          # print(f\"'{original}' might be a transposition. Suggestions: {corrections}\")\n",
        "      print(\"\\n\")\n",
        "  else:\n",
        "      print(\"No transposition errors found.\")\n",
        "  return"
      ],
      "metadata": {
        "id": "LDJo6dB2BpQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detect_letter_transpositions(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUaobsfyH4R8",
        "outputId": "e7508fec-06e5-49d6-dc5e-591306a228b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transposition Errors Found:\n",
            "Letter transposition detected: 'nosie' might be noise\n",
            "Letter transposition detected: 'littel' might be little\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jqa1JIxsFdzy"
      },
      "source": [
        "#3. Extract Homophone Confusion\n",
        "\n",
        "\n",
        "*  Description: Using the wrong word that sounds the same but is spelled differently.\n",
        "* Example: there instead of their\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code can't detect the correct form of the word! code Just sugested that we might be have error (for detect the complete error we need to know that this error is part of grammeral errors and we need to use another algorithms, so I ignore this error for this phase.\n",
        "I will implement this code for phase 2(the grammeral errors))"
      ],
      "metadata": {
        "id": "spgeTxUtdNKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text with homophone confusion\n",
        "text = \"\"\"\n",
        "Tim was playing in his yard when he heard a noise. It was a little puppy! The puppy was hiding and didn't have a collar.\n",
        "Tim thought the puppy was lost, so he took him home.\n",
        "He called the puppy Max. Tim’s parents said they had to find the owner, so they went to the animal shelter, but no one knew the puppy.\n",
        "In school, Tim loved physics and chemistry.\n",
        "He left his book over there, but he meant to take it with him to their house.\n",
        "\"\"\"\n",
        "def detect_homophone_confusion(word):\n",
        "\n",
        "\n",
        "  # Tokenize the text\n",
        "  tokens = nltk.word_tokenize(text.lower())\n",
        "\n",
        "  # A dictionary of common homophones\n",
        "  homophones = {\n",
        "      \"there\": {\"there\", \"their\", \"they're\"},\n",
        "      \"their\": {\"there\", \"their\", \"they're\"},\n",
        "      \"they're\": {\"there\", \"their\", \"they're\"},\n",
        "      \"your\": {\"your\", \"you're\"},\n",
        "      \"you're\": {\"your\", \"you're\"},\n",
        "      \"to\": {\"to\", \"too\", \"two\"},\n",
        "      \"too\": {\"to\", \"too\", \"two\"},\n",
        "      \"two\": {\"to\", \"too\", \"two\"},\n",
        "      \"its\": {\"its\", \"it's\"},\n",
        "      \"it's\": {\"its\", \"it's\"},\n",
        "      # Add more homophone sets as needed\n",
        "  }\n",
        "\n",
        "  # Function to detect homophone confusion\n",
        "  def detect_homophone_confusion(tokens):\n",
        "      homophone_errors = {}\n",
        "\n",
        "      for token in tokens:\n",
        "          # If the token is in the homophone dictionary, check for homophone confusion\n",
        "          if token in homophones:\n",
        "              homophone_set = homophones[token]\n",
        "              # Flagging as a possible confusion, since it's part of a homophone group\n",
        "              homophone_errors[token] = homophone_set\n",
        "\n",
        "      return homophone_errors\n",
        "\n",
        "  # Check the text for homophone confusion\n",
        "  homophone_confusions = detect_homophone_confusion(tokens)\n",
        "\n",
        "  # Print the homophone confusion errors found\n",
        "  if homophone_confusions:\n",
        "      print(\"Homophone Confusion Errors Found:\")\n",
        "      for word, homophone_set in homophone_confusions.items():\n",
        "          print(f\"'{word}' is part of the homophone set: {homophone_set}. Possible confusion.\")\n",
        "      print(\"\\n\")\n",
        "  else:\n",
        "      print(\"No homophone confusion errors found.\")\n",
        "  return None"
      ],
      "metadata": {
        "id": "GUPKF4S_ZEPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detect_homophone_confusion(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IigBc5Q8fXdt",
        "outputId": "6198aa5c-2f8f-4bff-8bc8-a92a41dcf1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Homophone Confusion Errors Found:\n",
            "'to' is part of the homophone set: {'too', 'two', 'to'}. Possible confusion.\n",
            "'there' is part of the homophone set: {\"they're\", 'there', 'their'}. Possible confusion.\n",
            "'their' is part of the homophone set: {\"they're\", 'there', 'their'}. Possible confusion.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBjEM0u3Fd_Q"
      },
      "source": [
        "#4. Extract Vowel Substitution\n",
        "\n",
        "*  Description: Incorrectly substituting vowels in words.\n",
        "* Example: hat instead of hit\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text\n",
        "text = \"\"\"\n",
        "Tim was playng in his yard wen he herd a nosie. It was a littel puppy! The puppy was hideing and didnt have a coller.\n",
        "Tim thot the puppy was lost so he toke him home.\n",
        "He calld the puppy Max. Tim’s parnts sed they had to find the ower so they went to the animel sheltur but no one knew the puppy.\n",
        "\"\"\"\n",
        "def detect_vowel_substitution(word):\n",
        "  # Define vowels for substitution\n",
        "  vowels = \"aeiou\"\n",
        "\n",
        "\n",
        "\n",
        "  # Tokenize the text\n",
        "  tokens = nltk.word_tokenize(text.lower())\n",
        "\n",
        "  # Function to detect vowel substitution errors\n",
        "  def detect_vowel_substitution(word):\n",
        "      # Check if the word is in the dictionary\n",
        "      if word in word_list:\n",
        "          return None  # Word is correct, no need to check for vowel substitution\n",
        "\n",
        "      substitution_candidates = set()\n",
        "\n",
        "      # Replace each vowel in the word with other vowels\n",
        "      for i, char in enumerate(word):\n",
        "          if char in vowels:\n",
        "              for vowel in vowels:\n",
        "                  if char != vowel:  # Only substitute with a different vowel\n",
        "                      substituted_word = word[:i] + vowel + word[i+1:]\n",
        "                      if substituted_word in word_list:\n",
        "                          substitution_candidates.add(substituted_word)\n",
        "\n",
        "      if substitution_candidates:\n",
        "          return substitution_candidates\n",
        "      else:\n",
        "          return None\n",
        "\n",
        "  # Check each word in the text for vowel substitutions\n",
        "  vowel_substitution_errors = {}\n",
        "  for token in tokens:\n",
        "      substitutions = detect_vowel_substitution(token)\n",
        "      if substitutions:\n",
        "          vowel_substitution_errors[token] = substitutions\n",
        "\n",
        "  # Print the vowel substitution errors found\n",
        "  if vowel_substitution_errors:\n",
        "      print(\"Vowel Substitution Errors Found:\")\n",
        "      for original, corrections in vowel_substitution_errors.items():\n",
        "          print(f\"'{original}' might have a vowel substitution. Suggestions: {corrections}\")\n",
        "      print(\"\\n\")\n",
        "  else:\n",
        "      print(\"No vowel substitution errors found.\")\n",
        "  return None"
      ],
      "metadata": {
        "id": "s3urMq4rSV2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detect_vowel_substitution(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yIWTbh1TD19",
        "outputId": "2269892c-0205-4948-ba58-9765302a085a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vowel Substitution Errors Found:\n",
            "'tim' might have a vowel substitution. Suggestions: {'tum', 'tam'}\n",
            "'coller' might have a vowel substitution. Suggestions: {'culler', 'caller', 'collar'}\n",
            "'thot' might have a vowel substitution. Suggestions: {'that'}\n",
            "'max' might have a vowel substitution. Suggestions: {'mix', 'mux'}\n",
            "'sed' might have a vowel substitution. Suggestions: {'sad', 'sod', 'sud'}\n",
            "'animel' might have a vowel substitution. Suggestions: {'animal'}\n",
            "'sheltur' might have a vowel substitution. Suggestions: {'shelter'}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9-7z6pzFeRK"
      },
      "source": [
        "#5. Extract Punctuation Omission\n",
        "\n",
        "\n",
        "*  Description: Missing punctuation, especially in contractions or possessives.\n",
        "* Example: cant instead of can't\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_2UcCTYTndt"
      },
      "outputs": [],
      "source": [
        "# List of common contractions\n",
        "contractions = {\"can't\": 'cannot', \"don't\": 'do not', \"didn't\": 'did not', \"won't\": 'will not', \"couldn't\":'could not', \"wasn't\":'was not'}\n",
        "\n",
        "\n",
        "# Function to detect Punctuation Omission (e.g., \"cant\" instead of \"can't\")\n",
        "def detect_punctuation_omission(word):\n",
        "    if word in contractions.keys():\n",
        "        return None  # Word is a valid contraction\n",
        "    for contraction, full_word in contractions.items():\n",
        "        if word == contraction.replace(\"'\", \"\"):\n",
        "            return f\"Punctuation omission detected:\\n'{word}' might be '{contraction}'\"\n",
        "\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaLoW_cOFee5"
      },
      "source": [
        "#6. Extract Grapheme-Phoneme Confusion\n",
        "\n",
        "\n",
        "*  Description: Difficulty matching sounds (phonemes) to the correct letters or letter combinations (graphemes).\n",
        "* Example: fiziks instead of physics\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install metaphone\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fegxIG6hXZ85",
        "outputId": "293ee3ec-6d47-4d59-d296-5f5102bf90ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting metaphone\n",
            "  Downloading Metaphone-0.6.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: metaphone\n",
            "  Building wheel for metaphone (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for metaphone: filename=Metaphone-0.6-py3-none-any.whl size=13900 sha256=80ade2252937e97f1bbbdd5eba10afcaddc4ecbc88bd49b6f5aa75a9577ef718\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/dd/1d/6cdd346605db62bde1f60954155e9ce48f4681c243f265b704\n",
            "Successfully built metaphone\n",
            "Installing collected packages: metaphone\n",
            "Successfully installed metaphone-0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import words\n",
        "from nltk.metrics import edit_distance\n",
        "from metaphone import doublemetaphone"
      ],
      "metadata": {
        "id": "zIKOwl2WXibt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A list of valid English words\n",
        "word_list = set(words.words())\n",
        "\n",
        "# Sample text\n",
        "text = \"\"\"\n",
        "fizics Tim was playng in his yard wen he herd a nosie. It was a littel puppy! The puppy was hideing and didnt have a coller.\n",
        "Tim thot the puppy was lost so he toke him home.\n",
        "He calld the puppy Max. Tim’s parnts sed they had to find the ower so they went to the animel sheltur but no one knew the puppy.\n",
        "In school, Tim loved fiziks and chemestry.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(text.lower())\n",
        "def detect_grapheme_phoneme(word):\n",
        "  # Function to detect grapheme-phoneme confusion using Metaphone\n",
        "  def detect_grapheme_phoneme_confusion(word):\n",
        "      # Check if the word is in the dictionary\n",
        "      if word in word_list:\n",
        "          return None  # Word is correct, no need to check for confusion\n",
        "\n",
        "      # Get the Metaphone encoding of the input word\n",
        "      word_metaphone = doublemetaphone(word)[0]\n",
        "\n",
        "      # Find valid dictionary words with the same Metaphone code\n",
        "      candidates = [w for w in word_list if doublemetaphone(w)[0] == word_metaphone]\n",
        "\n",
        "      if candidates:\n",
        "          return candidates[0]  # Return the first matching word\n",
        "      else:\n",
        "          return None\n",
        "\n",
        "  # Check each word in the text for grapheme-phoneme confusion\n",
        "  grapheme_phoneme_errors = {}\n",
        "  for token in tokens:\n",
        "      correction = detect_grapheme_phoneme_confusion(token)\n",
        "      if correction:\n",
        "          grapheme_phoneme_errors[token] = correction\n",
        "\n",
        "  # Print the grapheme-phoneme confusion errors found\n",
        "  if grapheme_phoneme_errors:\n",
        "      print(\"Grapheme-Phoneme Confusion Errors Found:\")\n",
        "      for original, correction in grapheme_phoneme_errors.items():\n",
        "          print(f\"'{original}' might be a phonetic confusion. Suggested correction: '{correction}'\")\n",
        "  else:\n",
        "      print(\"No grapheme-phoneme confusion errors found.\")\n",
        "  return None\n"
      ],
      "metadata": {
        "id": "sJAAxwqpXcTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(text.lower())\n",
        "\n",
        "# Function to detect grapheme-phoneme confusion using Metaphone\n",
        "def detect_grapheme_phoneme_confusion(word):\n",
        "    # If the word is already a valid word, no correction is needed\n",
        "    if word in word_list:\n",
        "        return None\n",
        "\n",
        "    # Get the Metaphone encoding of the input word (primary encoding)\n",
        "    word_metaphone = doublemetaphone(word)[0]\n",
        "\n",
        "    # Find valid words with the same Metaphone code\n",
        "    for w in word_list:\n",
        "        if doublemetaphone(w)[0] == word_metaphone:\n",
        "            return w  # Return the first valid matching word\n",
        "\n",
        "    return None\n",
        "\n",
        "# Check each word in the text for grapheme-phoneme confusion\n",
        "grapheme_phoneme_errors = {}\n",
        "for token in tokens:\n",
        "    correction = detect_grapheme_phoneme_confusion(token)\n",
        "    if correction:\n",
        "        grapheme_phoneme_errors[token] = correction\n",
        "\n",
        "# Print the grapheme-phoneme confusion errors found\n",
        "if grapheme_phoneme_errors:\n",
        "    print(\"Grapheme-Phoneme Confusion Errors Found:\")\n",
        "    for original, correction in grapheme_phoneme_errors.items():\n",
        "        print(f\"'{original}' might be a phonetic confusion. Suggested correction: '{correction}'\")\n",
        "else:\n",
        "    print(\"No grapheme-phoneme confusion errors found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vTykZC7YXry",
        "outputId": "8e52d059-8352-415c-dbac-c841f55f2e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grapheme-Phoneme Confusion Errors Found:\n",
            "'fizics' might be a phonetic confusion. Suggested correction: 'Phascaceae'\n",
            "'tim' might be a phonetic confusion. Suggested correction: 'taum'\n",
            "'playng' might be a phonetic confusion. Suggested correction: 'blink'\n",
            "'nosie' might be a phonetic confusion. Suggested correction: 'Nosu'\n",
            "'.' might be a phonetic confusion. Suggested correction: 'W'\n",
            "'littel' might be a phonetic confusion. Suggested correction: 'lootiewallah'\n",
            "'!' might be a phonetic confusion. Suggested correction: 'W'\n",
            "'hideing' might be a phonetic confusion. Suggested correction: 'hatting'\n",
            "'coller' might be a phonetic confusion. Suggested correction: 'glower'\n",
            "'thot' might be a phonetic confusion. Suggested correction: 'thwaite'\n",
            "'calld' might be a phonetic confusion. Suggested correction: 'collate'\n",
            "'max' might be a phonetic confusion. Suggested correction: 'mycose'\n",
            "'’' might be a phonetic confusion. Suggested correction: 'W'\n",
            "'parnts' might be a phonetic confusion. Suggested correction: 'brandise'\n",
            "'sed' might be a phonetic confusion. Suggested correction: 'zooid'\n",
            "'animel' might be a phonetic confusion. Suggested correction: 'Anomala'\n",
            "'sheltur' might be a phonetic confusion. Suggested correction: 'Chelydra'\n",
            "',' might be a phonetic confusion. Suggested correction: 'W'\n",
            "'loved' might be a phonetic confusion. Suggested correction: 'leaved'\n",
            "'fiziks' might be a phonetic confusion. Suggested correction: 'Phascaceae'\n",
            "'chemestry' might be a phonetic confusion. Suggested correction: 'chemistry'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #with Soundex(doesn't work for now)\n",
        "# import fuzzy\n",
        "# # A list of valid English words\n",
        "# word_list = set(words.words())\n",
        "\n",
        "# # Initialize Soundex\n",
        "# soundex = fuzzy.Soundex(4)\n",
        "\n",
        "# # Sample text\n",
        "# text = \"\"\"\n",
        "# fizics Tim was playng in his yard wen he herd a nosie. It was a littel puppy! The puppy was hideing and didnt have a coller.\n",
        "# Tim thot the puppy was lost so he toke him home.\n",
        "# He calld the puppy Max. Tim’s parnts sed they had to find the ower so they went to the animel sheltur but no one knew the puppy.\n",
        "# In school, Tim loved fiziks and chemestry.\n",
        "# \"\"\"\n",
        "\n",
        "# # Tokenize the text\n",
        "# tokens = nltk.word_tokenize(text.lower())\n",
        "\n",
        "# # Function to detect grapheme-phoneme confusion\n",
        "# def detect_grapheme_phoneme_confusion(word):\n",
        "#     # Check if the word is in the dictionary\n",
        "#     if word in word_list:\n",
        "#         return None  # Word is correct, no need to check for confusion\n",
        "\n",
        "#     # Get the Soundex code of the input word\n",
        "#     word_soundex = soundex(word)\n",
        "\n",
        "#     # Find valid dictionary words with the same Soundex code\n",
        "#     candidates = [w for w in word_list if soundex(w) == word_soundex]\n",
        "\n",
        "#     if candidates:\n",
        "#         return candidates[0]  # Return the first matching word\n",
        "#     else:\n",
        "#         return None\n",
        "\n",
        "# # Check each word in the text for grapheme-phoneme confusion\n",
        "# grapheme_phoneme_errors = {}\n",
        "# for token in tokens:\n",
        "#     correction = detect_grapheme_phoneme_confusion(token)\n",
        "#     if correction:\n",
        "#         grapheme_phoneme_errors[token] = correction\n",
        "\n",
        "# # Print the grapheme-phoneme confusion errors found\n",
        "# if grapheme_phoneme_errors:\n",
        "#     print(\"Grapheme-Phoneme Confusion Errors Found:\")\n",
        "#     for original, correction in grapheme_phoneme_errors.items():\n",
        "#         print(f\"'{original}' might be a phonetic confusion. Suggested correction: '{correction}'\")\n",
        "# else:\n",
        "#     print(\"No grapheme-phoneme confusion errors found.\")\n"
      ],
      "metadata": {
        "id": "pAU7tseRVWr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## not finished!\n",
        "\n",
        "*double consonant confusion*"
      ],
      "metadata": {
        "id": "-HdrkU2wqaE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download words corpus if necessary\n",
        "nltk.download('words')\n",
        "\n",
        "# List of English words from NLTK\n",
        "word_list = set(nltk.corpus.words.words())\n",
        "\n",
        "# Sample text containing possible double consonant confusion\n",
        "text = \"\"\"\n",
        "Tim was stoping by the store to get some supplies. He was also planing a trip for the weekend.\n",
        "The puppy was running around and jumping everywhere.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(text.lower())\n",
        "\n",
        "# Function to detect double consonant confusion\n",
        "def detect_double_consonant_confusion(word):\n",
        "    # If the word is valid (in dictionary), return None\n",
        "    if word in word_list:\n",
        "        return None\n",
        "\n",
        "    # Check if the word is missing a double consonant\n",
        "    for i in range(1, len(word)):\n",
        "        # If there is a consonant followed by the same consonant (i.e., double consonant)\n",
        "        if word[i] == word[i - 1] and word[i] in \"bcdfghjklmnpqrstvwxyz\":\n",
        "            return None  # This word already has the double consonant, no confusion\n",
        "\n",
        "    # Now check for possible confusion with valid words that contain double consonants\n",
        "    for w in word_list:\n",
        "        if len(w) == len(word) + 1 and w.startswith(word[:-1]) and w[-1] == w[-2]:\n",
        "            return w  # Return the correct word with the double consonant\n",
        "\n",
        "    return None\n",
        "\n",
        "# Check each word in the text for double consonant confusion\n",
        "double_consonant_errors = {}\n",
        "for token in tokens:\n",
        "    correction = detect_double_consonant_confusion(token)\n",
        "    if correction:\n",
        "        double_consonant_errors[token] = correction\n",
        "\n",
        "# Print the double consonant confusion errors found\n",
        "if double_consonant_errors:\n",
        "    print(\"Double Consonant Confusion Errors Found:\")\n",
        "    for original, correction in double_consonant_errors.items():\n",
        "        print(f\"'{original}' might be missing a double consonant. Suggested correction: '{correction}'\")\n",
        "else:\n",
        "    print(\"No double consonant confusion errors found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2HkLg5qn4GP",
        "outputId": "27a9814b-4599-4fbd-960f-9f93939322d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Double Consonant Confusion Errors Found:\n",
            "'tim' might be missing a double consonant. Suggested correction: 'till'\n",
            "'.' might be missing a double consonant. Suggested correction: 'aa'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "\n",
        "# Download words corpus if necessary\n",
        "nltk.download('words')\n",
        "\n",
        "# List of English words from NLTK\n",
        "word_list = set(nltk.corpus.words.words())\n",
        "\n",
        "# Sample text containing possible double consonant confusion\n",
        "text = \"\"\"\n",
        "Tim was stoping by the store to get some supplies. He was also planing a trip for the weekend.\n",
        "The puppy was running around and jumping everywhere.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(text.lower())\n",
        "\n",
        "# Regular expression to identify words that may need double consonants before 'ing' or 'ed'\n",
        "double_consonant_pattern = re.compile(r'([bcdfghjklmnpqrstvwxyz])([aeiou])([bcdfghjklmnpqrstvwxyz])(?:ing|ed)$')\n",
        "\n",
        "# Function to detect double consonant confusion\n",
        "def detect_double_consonant_confusion(word):\n",
        "    if word in word_list:\n",
        "        return None\n",
        "\n",
        "    match = double_consonant_pattern.match(word)\n",
        "    if match:\n",
        "        # Extract consonants and vowel parts\n",
        "        first_consonant, vowel, last_consonant = match.groups()\n",
        "\n",
        "        # Form the correct double consonant word\n",
        "        correct_word = word.replace(last_consonant, last_consonant * 2)\n",
        "\n",
        "        # Check if the corrected word exists in the dictionary\n",
        "        if correct_word in word_list:\n",
        "            return correct_word\n",
        "\n",
        "    return None\n",
        "\n",
        "# Check each word in the text for double consonant confusion\n",
        "double_consonant_errors = {}\n",
        "for token in tokens:\n",
        "    correction = detect_double_consonant_confusion(token)\n",
        "    if correction:\n",
        "        double_consonant_errors[token] = correction\n",
        "\n",
        "# Print the double consonant confusion errors found\n",
        "if double_consonant_errors:\n",
        "    print(\"Double Consonant Confusion Errors Found:\")\n",
        "    for original, correction in double_consonant_errors.items():\n",
        "        print(f\"'{original}' might be missing a double consonant. Suggested correction: '{correction}'\")\n",
        "else:\n",
        "    print(\"No double consonant confusion errors found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRF3t6LCoR3C",
        "outputId": "54f6507b-bf59-4d0c-ba07-b6d8e005698b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No double consonant confusion errors found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re"
      ],
      "metadata": {
        "id": "VShKnEONpLGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Download words corpus if necessary\n",
        "nltk.download('words')\n",
        "\n",
        "# List of valid English words from NLTK\n",
        "word_list = set(nltk.corpus.words.words())\n",
        "\n",
        "# Sample text containing possible double consonant confusion\n",
        "text = \"\"\"\n",
        "Tim was stoping by the store to get some supplies. He was also planing a trip for the weekend.\n",
        "The puppy was running around and jumping everywhere.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(text.lower())\n",
        "\n",
        "# Regular expression to match words with a single consonant before suffixes like \"ing\" or \"ed\"\n",
        "double_consonant_pattern = re.compile(r'([bcdfghjklmnpqrstvwxyz])([aeiou])([bcdfghjklmnpqrstvwxyz])(ing|ed|er)$')\n",
        "\n",
        "# Function to detect double consonant confusion\n",
        "def detect_double_consonant_confusion(word):\n",
        "    # Check if the word is already valid\n",
        "    if word in word_list:\n",
        "        return None\n",
        "\n",
        "    # Check for potential missing double consonants using regex\n",
        "    match = double_consonant_pattern.search(word)\n",
        "    if match:\n",
        "        first_consonant, vowel, last_consonant, suffix = match.groups()\n",
        "\n",
        "        # Form the correct double consonant version of the word\n",
        "        corrected_word = word.replace(last_consonant + suffix, last_consonant * 2 + suffix)\n",
        "\n",
        "        # Check if the corrected word is in the dictionary\n",
        "        if corrected_word in word_list:\n",
        "            return corrected_word\n",
        "\n",
        "    return None\n",
        "\n",
        "# Check each word in the text for double consonant confusion\n",
        "double_consonant_errors = {}\n",
        "for token in tokens:\n",
        "    correction = detect_double_consonant_confusion(token)\n",
        "    if correction:\n",
        "        double_consonant_errors[token] = correction\n",
        "\n",
        "# Print the double consonant confusion errors found\n",
        "if double_consonant_errors:\n",
        "    print(\"Double Consonant Confusion Errors Found:\")\n",
        "    for original, correction in double_consonant_errors.items():\n",
        "        print(f\"'{original}' might be missing a double consonant. Suggested correction: '{correction}'\")\n",
        "else:\n",
        "    print(\"No double consonant confusion errors found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "673NW9I9pHp6",
        "outputId": "bd1e65e5-c2ac-47c6-eb54-cf9db6e57a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No double consonant confusion errors found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.Extreact visual similarity errors"
      ],
      "metadata": {
        "id": "HQxAj5K-vhaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Download the words corpus if necessary\n",
        "nltk.download('words')\n",
        "\n",
        "# List of valid English words from NLTK\n",
        "word_list = set(nltk.corpus.words.words())\n",
        "\n",
        "# Sample text containing possible visual similarity confusion\n",
        "text = \"\"\"\n",
        "Tim saw a qen outside the window. He also mistook his pen for a qencil. The little puppy was barking at the big bog. lmportant things\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(text.lower())\n",
        "def detect_visual_similarity_confusion(word):\n",
        "  # Dictionary of visually similar letters\n",
        "  visual_similarity = {\n",
        "      'b': 'd', 'd': 'b',\n",
        "      'p': 'q', 'q': 'p',\n",
        "      'i': 'l', 'l': 'i',\n",
        "      'v': 'w', 'w': 'v',\n",
        "      'c': 'e', 'e': 'c'\n",
        "  }\n",
        "\n",
        "  # Function to detect visual similarity confusion\n",
        "  def detect(word):\n",
        "      if word in word_list:\n",
        "          return None, None\n",
        "\n",
        "      # List to store possible corrections\n",
        "      possible_corrections = []\n",
        "\n",
        "      # Try replacing each letter with its visually similar counterpart\n",
        "      for i, letter in enumerate(word):\n",
        "          if letter in visual_similarity:\n",
        "              # Substitute with the visually similar letter\n",
        "              new_word = word[:i] + visual_similarity[letter] + word[i+1:]\n",
        "\n",
        "              # Check if the new word exists in the dictionary\n",
        "              if new_word in word_list:\n",
        "                  possible_corrections.append(new_word)\n",
        "\n",
        "      if possible_corrections:\n",
        "          # Return the first valid correction and the error type\n",
        "          return possible_corrections[0], \"Visual similarity confusion\"\n",
        "\n",
        "      return None, None\n",
        "\n",
        "  # Check each word in the text for visual similarity confusion\n",
        "  visual_similarity_errors = {}\n",
        "  for token in tokens:\n",
        "      correction, error_type = detect(token)\n",
        "      if correction:\n",
        "          visual_similarity_errors[token] = {\n",
        "              'correct_word': correction,\n",
        "              'error_type': error_type\n",
        "          }\n",
        "\n",
        "  # Print the visual similarity confusion errors found with details\n",
        "  if visual_similarity_errors:\n",
        "      print(\"Visual Similarity Confusion Errors Found:\")\n",
        "      for incorrect_word, details in visual_similarity_errors.items():\n",
        "          print(f\"Incorrect Word: '{incorrect_word}'\")\n",
        "          print(f\"Correct Word: '{details['correct_word']}'\")\n",
        "          print(f\"Error Type: {details['error_type']}\")\n",
        "          print(\"---\")\n",
        "\n",
        "  else:\n",
        "      print(\"No visual similarity confusion errors found.\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  return None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ1z5j2iqnr1",
        "outputId": "2f520cf7-004e-4263-c680-f86c46e783d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detect_visual_similarity_confusion(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o43ymY81spgN",
        "outputId": "e36de489-810c-4a76-b5d1-51cf55646b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visual Similarity Confusion Errors Found:\n",
            "Incorrect Word: 'qen'\n",
            "Correct Word: 'pen'\n",
            "Error Type: Visual similarity confusion\n",
            "---\n",
            "Incorrect Word: 'qencil'\n",
            "Correct Word: 'pencil'\n",
            "Error Type: Visual similarity confusion\n",
            "---\n",
            "Incorrect Word: 'lmportant'\n",
            "Correct Word: 'important'\n",
            "Error Type: Visual similarity confusion\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Ectract word_boundary_errors"
      ],
      "metadata": {
        "id": "ekXPpQd1xK4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_word_boundary_errors = {\n",
        "    # Commonly combined words\n",
        "    \"alot\": [\"a\", \"lot\"],\n",
        "    \"infact\": [\"in\", \"fact\"],\n",
        "    \"theres\": [\"there\", \"is\"],\n",
        "    \"heres\": [\"here\", \"is\"],\n",
        "    \"its\": [\"it\", \"is\"],  # When incorrectly combined without apostrophe\n",
        "    \"lets\": [\"let\", \"us\"],\n",
        "    \"whos\": [\"who\", \"is\"],  # When not used as possessive\n",
        "    \"im\": [\"i\", \"am\"],\n",
        "    \"youre\": [\"you\", \"are\"],\n",
        "    \"theyre\": [\"they\", \"are\"],\n",
        "    \"were\": [\"we\", \"are\"],  # In case it's mistaken with \"we're\"\n",
        "\n",
        "    # Other cases often confused or mistakenly joined\n",
        "    \"inorder\": [\"in\", \"order\"],\n",
        "    \"thankyou\": [\"thank\", \"you\"],\n",
        "    \"eachother\": [\"each\", \"other\"],\n",
        "    \"nomatter\": [\"no\", \"matter\"],\n",
        "    \"aswell\": [\"as\", \"well\"],\n",
        "    \"allright\": [\"all\", \"right\"],  # Variation of alright\n",
        "    \"anymore\": [\"any\", \"more\"],  # For certain dialects\n",
        "    \"anyway\": [\"any\", \"way\"],  # Some dialects use \"anyways\"\n",
        "    \"nevermind\": [\"never\", \"mind\"],\n",
        "    \"alotof\": [\"a\", \"lot\", \"of\"],  # When students combine the phrase into one word\n",
        "    \"kindof\": [\"kind\", \"of\"],  # Informal writing mistake\n",
        "    \"sortof\": [\"sort\", \"of\"],\n",
        "    \"mustnt\": [\"must\", \"not\"],  # Variations of negations with contractions\n",
        "    \"havent\": [\"have\", \"not\"],\n",
        "    \"hasnt\": [\"has\", \"not\"],\n",
        "    \"whered\": [\"where\", \"did\"],  # Common question forms\n",
        "    \"howd\": [\"how\", \"did\"],\n",
        "    \"whyd\": [\"why\", \"did\"],\n",
        "    \"whats\": [\"what\", \"is\"],  # When improperly contracted\n",
        "    \"gonna\": [\"going\", \"to\"],  # Informal but might be confused as one word\n",
        "    \"wanna\": [\"want\", \"to\"],\n",
        "    \"hafta\": [\"have\", \"to\"],  # Informal pronunciation but often written together\n",
        "}\n"
      ],
      "metadata": {
        "id": "SpL9QoySwVeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Download the words corpus if necessary\n",
        "nltk.download('words')\n",
        "\n",
        "# List of valid English words from NLTK\n",
        "word_list = set(nltk.corpus.words.words())\n",
        "\n",
        "# Sample text containing possible word boundary errors\n",
        "text = \"\"\"\n",
        "Tim thought alot about the puppy. He didnt know if infact the puppy belonged to someone.\n",
        "He said it was alright and went outside to see if theres anyone around. He thought alotof people would notice. He also said thankyou to the people helping.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(text.lower())\n",
        "def detect_word_boundary_errors(word):\n",
        "  # Function to detect word boundary errors\n",
        "  def detect_word_b(word):\n",
        "      if word in common_word_boundary_errors:\n",
        "          correct_split = common_word_boundary_errors[word]\n",
        "          # Check if all parts exist in the word list\n",
        "          if all(part in word_list for part in correct_split):\n",
        "              return ' '.join(correct_split), \"Word boundary error\"\n",
        "\n",
        "      return None, None\n",
        "\n",
        "  # Check each word in the text for word boundary errors\n",
        "  word_boundary_errors = {}\n",
        "  for token in tokens:\n",
        "      correction, error_type = detect_word_b(token)\n",
        "      if correction:\n",
        "          word_boundary_errors[token] = {\n",
        "              'correct_word': correction,\n",
        "              'error_type': error_type\n",
        "          }\n",
        "\n",
        "  # Print the word boundary confusion errors found with details\n",
        "  if word_boundary_errors:\n",
        "      print(\"Word Boundary Errors Found:\")\n",
        "      for incorrect_word, details in word_boundary_errors.items():\n",
        "          print(f\"Incorrect Word: '{incorrect_word}'\")\n",
        "          print(f\"Correct Word: '{details['correct_word']}'\")\n",
        "          print(f\"Error Type: {details['error_type']}\")\n",
        "          print(\"---\")\n",
        "  else:\n",
        "      print(\"No word boundary errors found.\")\n",
        "  print(\"\\n\")\n",
        "  return None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmdKYT6Pv7Wp",
        "outputId": "1fe51c73-77e5-48c6-90ff-89ee96335d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detect_word_boundary_errors(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMGG5-lixmyh",
        "outputId": "044df695-df36-4c81-8853-835aa8bb97ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Boundary Errors Found:\n",
            "Incorrect Word: 'alot'\n",
            "Correct Word: 'a lot'\n",
            "Error Type: Word boundary error\n",
            "---\n",
            "Incorrect Word: 'infact'\n",
            "Correct Word: 'in fact'\n",
            "Error Type: Word boundary error\n",
            "---\n",
            "Incorrect Word: 'theres'\n",
            "Correct Word: 'there is'\n",
            "Error Type: Word boundary error\n",
            "---\n",
            "Incorrect Word: 'alotof'\n",
            "Correct Word: 'a lot of'\n",
            "Error Type: Word boundary error\n",
            "---\n",
            "Incorrect Word: 'thankyou'\n",
            "Correct Word: 'thank you'\n",
            "Error Type: Word boundary error\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4qFav6KKYDh"
      },
      "source": [
        "# Final Step:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"One Saturday morning, Tim was playing in his backyard when he heard a soft whimper. He looked around and saw a small, scared puppy hiding behind a bush. The puppy didn’t have a collar, so Tim thought it must be lost. He carefully walked up to the puppy, talking softly so it wouldn’t be scared. The puppy wagged its tail and slowly came out. Tim decided to take it home and named it Max.\n",
        "When Tim’s parents saw the puppy, they said he could keep it for now, but they had to find the owner first. They took Max to the animal shelter to check if anyone had reported him missing, but no one had. Tim’s family put up posters around the neighborhood, hoping someone would come forward. Days went by, and no one claimed Max, so Tim kept playing with him every day. He loved Max and was excited to have a dog.\n",
        "But one day, when Tim was at the park with Max, a little girl ran up to him. She looked at Max and shouted, \"That’s my dog!\" Tim felt sad. The girl told him that Max’s real name was Buddy, and he had run away from home about a week ago. Even though Tim didn’t want to let Max go, he knew it was the right thing to do. So, the next day, Tim and his parents took Max to the girl’s house, and Tim said goodbye.\n",
        "It was hard to say goodbye, but Tim was proud that he did the right thing. A few days later, Tim’s parents surprised him by adopting a new puppy from the animal shelter. Tim named the new dog Lucky, and even though he missed Max, he was happy to have another dog to play with.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Y_DESwa5uTI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text\n",
        "text =  \"\"\"\n",
        "Tim was playng in his yard wen he herd a nosie. It was a littel puppy! The puppy was hideing and didnt have a coller.\n",
        "Tim thot the puppy was lost so he toke him home.\n",
        "He calld the puppy Max. Tim’s parnts sed they had to find the ower so they went to the animel sheltur but no one knew the puppy. he saw a qen! outside the window.\n",
        "He also mistook his pen for a qencil and it was lmportant mistake!\n",
        "Tim thought alot about the puppy. He didnt know if infact the puppy belonged to someone.\n",
        "He said it was alright and went outside to see if theres anyone around. He thought alotof people would notice. He also said thankyou to the people helping.\n",
        "\"\"\"\n",
        "tokens = nltk.word_tokenize(text.lower())"
      ],
      "metadata": {
        "id": "fCfxueKwgmVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpgvFsVpUTgT"
      },
      "outputs": [],
      "source": [
        "\n",
        "def detect_errors(text):\n",
        "    words_list = re.findall(r'\\b\\w+\\b', text.lower())  # Basic tokenization\n",
        "    detect_letter_transpositions(text)\n",
        "    detect_vowel_substitution(text)\n",
        "    detect_letter_omission(text)\n",
        "    detect_homophone_confusion(text)\n",
        "    detect_visual_similarity_confusion(text)\n",
        "    detect_word_boundary_errors(text)\n",
        "    for word in words_list:\n",
        "        error_checks = [\n",
        "            detect_punctuation_omission(word),\n",
        "            # detect_phonetic_spelling(word),\n",
        "        ]\n",
        "        for error in error_checks:\n",
        "            if error:\n",
        "                print(error)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVsJjVQmU4Bu",
        "outputId": "f35f39d3-6afd-4bf4-c1f2-d75526d5f7fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transposition Errors Found:\n",
            "Letter transposition detected: 'nosie' might be noise\n",
            "Letter transposition detected: 'littel' might be little\n",
            "Letter transposition detected: 'alot' might be alto\n",
            "\n",
            "\n",
            "Vowel Substitution Errors Found:\n",
            "'tim' might have a vowel substitution. Suggestions: {'tum', 'tam'}\n",
            "'coller' might have a vowel substitution. Suggestions: {'culler', 'caller', 'collar'}\n",
            "'thot' might have a vowel substitution. Suggestions: {'that'}\n",
            "'max' might have a vowel substitution. Suggestions: {'mix', 'mux'}\n",
            "'sed' might have a vowel substitution. Suggestions: {'sad', 'sod', 'sud'}\n",
            "'animel' might have a vowel substitution. Suggestions: {'animal'}\n",
            "'sheltur' might have a vowel substitution. Suggestions: {'shelter'}\n",
            "'alot' might have a vowel substitution. Suggestions: {'ilot', 'alit'}\n",
            "'infact' might have a vowel substitution. Suggestions: {'infect', 'unfact'}\n",
            "\n",
            "\n",
            "Omission Errors Found:\n",
            "'tim' might have a letter omitted. Suggestions: {'trim', 'time', 'stim'}\n",
            "'nosie' might have a letter omitted. Suggestions: {'nosine'}\n",
            "'hideing' might have a letter omitted. Suggestions: {'hideling'}\n",
            "'coller' might have a letter omitted. Suggestions: {'collier', 'choller', 'collery'}\n",
            "'thot' might have a letter omitted. Suggestions: {'thowt', 'thoft', 'thort'}\n",
            "'calld' might have a letter omitted. Suggestions: {'callid'}\n",
            "'max' might have a letter omitted. Suggestions: {'maux'}\n",
            "'sed' might have a letter omitted. Suggestions: {'seed', 'used', 'sned', 'sped', 'send', 'sled', 'shed'}\n",
            "'alot' might have a letter omitted. Suggestions: {'allot', 'aloft'}\n",
            "'infact' might have a letter omitted. Suggestions: {'infract', 'infarct'}\n",
            "\n",
            "\n",
            "Homophone Confusion Errors Found:\n",
            "'to' is part of the homophone set: {'too', 'two', 'to'}. Possible confusion.\n",
            "\n",
            "\n",
            "Visual Similarity Confusion Errors Found:\n",
            "Incorrect Word: 'coller'\n",
            "Correct Word: 'coiler'\n",
            "Error Type: Visual similarity confusion\n",
            "---\n",
            "Incorrect Word: 'calld'\n",
            "Correct Word: 'calid'\n",
            "Error Type: Visual similarity confusion\n",
            "---\n",
            "Incorrect Word: 'qen'\n",
            "Correct Word: 'pen'\n",
            "Error Type: Visual similarity confusion\n",
            "---\n",
            "Incorrect Word: 'qencil'\n",
            "Correct Word: 'pencil'\n",
            "Error Type: Visual similarity confusion\n",
            "---\n",
            "Incorrect Word: 'lmportant'\n",
            "Correct Word: 'important'\n",
            "Error Type: Visual similarity confusion\n",
            "---\n",
            "\n",
            "\n",
            "Word Boundary Errors Found:\n",
            "Incorrect Word: 'alot'\n",
            "Correct Word: 'a lot'\n",
            "Error Type: Word boundary error\n",
            "---\n",
            "Incorrect Word: 'infact'\n",
            "Correct Word: 'in fact'\n",
            "Error Type: Word boundary error\n",
            "---\n",
            "Incorrect Word: 'theres'\n",
            "Correct Word: 'there is'\n",
            "Error Type: Word boundary error\n",
            "---\n",
            "Incorrect Word: 'alotof'\n",
            "Correct Word: 'a lot of'\n",
            "Error Type: Word boundary error\n",
            "---\n",
            "Incorrect Word: 'thankyou'\n",
            "Correct Word: 'thank you'\n",
            "Error Type: Word boundary error\n",
            "---\n",
            "\n",
            "\n",
            "Punctuation omission detected:\n",
            "'didnt' might be 'didn't'\n",
            "Punctuation omission detected:\n",
            "'didnt' might be 'didn't'\n"
          ]
        }
      ],
      "source": [
        "detect_errors(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normal kid\n",
        "text1=\"\"\"One Saturday morning, Tim was playing in his backyard when he heard a soft whimper. He looked around and saw a small, scared puppy hiding behind a bush. The puppy didn’t have a collar, so Tim thought it must be lost. He carefully walked up to the puppy, talking softly so it wouldn’t be scared. The puppy wagged its tail and slowly came out. Tim decided to take it home and named it Max.\n",
        "When Tim’s parents saw the puppy, they said he could keep it for now, but they had to find the owner first. They took Max to the animal shelter to check if anyone had reported him missing, but no one had. Tim’s family put up posters around the neighborhood, hoping someone would come forward. Days went by, and no one claimed Max, so Tim kept playing with him every day. He loved Max and was excited to have a dog.\n",
        "But one day, when Tim was at the park with Max, a little girl ran up to him. She looked at Max and shouted, \"That’s my dog!\" Tim felt sad. The girl told him that Max’s real name was Buddy, and he had run away from home about a week ago. Even though Tim didn’t want to let Max go, he knew it was the right thing to do. So, the next day, Tim and his parents took Max to the girl’s house, and Tim said goodbye.\n",
        "It was hard to say goodbye, but Tim was proud that he did the right thing. A few days later, Tim’s parents surprised him by adopting a new puppy from the animal shelter. Tim named the new dog Lucky, and even though he missed Max, he was happy to have another dog to play with.\n",
        "\"\"\"\n",
        "tokens = nltk.word_tokenize(text.lower())"
      ],
      "metadata": {
        "id": "UA8VRH2pt394"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detect_errors(text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOOHsFVht5Zv",
        "outputId": "9a390bfd-e78c-4594-b94e-b30e3faf7250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transposition Errors Found:\n",
            "Letter transposition detected: 'nosie' might be noise\n",
            "Letter transposition detected: 'littel' might be little\n",
            "\n",
            "\n",
            "Vowel Substitution Errors Found:\n",
            "'tim' might have a vowel substitution. Suggestions: {'tum', 'tam'}\n",
            "'coller' might have a vowel substitution. Suggestions: {'culler', 'caller', 'collar'}\n",
            "'thot' might have a vowel substitution. Suggestions: {'that'}\n",
            "'max' might have a vowel substitution. Suggestions: {'mix', 'mux'}\n",
            "'sed' might have a vowel substitution. Suggestions: {'sad', 'sod', 'sud'}\n",
            "'animel' might have a vowel substitution. Suggestions: {'animal'}\n",
            "'sheltur' might have a vowel substitution. Suggestions: {'shelter'}\n",
            "\n",
            "\n",
            "Omission Errors Found:\n",
            "'tim' might have a letter omitted. Suggestions: {'trim', 'time', 'stim'}\n",
            "'nosie' might have a letter omitted. Suggestions: {'nosine'}\n",
            "'hideing' might have a letter omitted. Suggestions: {'hideling'}\n",
            "'coller' might have a letter omitted. Suggestions: {'collier', 'choller', 'collery'}\n",
            "'thot' might have a letter omitted. Suggestions: {'thowt', 'thoft', 'thort'}\n",
            "'calld' might have a letter omitted. Suggestions: {'callid'}\n",
            "'max' might have a letter omitted. Suggestions: {'maux'}\n",
            "'sed' might have a letter omitted. Suggestions: {'seed', 'used', 'sned', 'sped', 'send', 'sled', 'shed'}\n",
            "\n",
            "\n",
            "Homophone Confusion Errors Found:\n",
            "'to' is part of the homophone set: {'too', 'two', 'to'}. Possible confusion.\n",
            "\n",
            "\n",
            "Visual Similarity Confusion Errors Found:\n",
            "Incorrect Word: 'coller'\n",
            "Correct Word: 'coiler'\n",
            "Error Type: Visual similarity confusion\n",
            "---\n",
            "Incorrect Word: 'calld'\n",
            "Correct Word: 'calid'\n",
            "Error Type: Visual similarity confusion\n",
            "---\n",
            "Incorrect Word: 'qen'\n",
            "Correct Word: 'pen'\n",
            "Error Type: Visual similarity confusion\n",
            "---\n",
            "Incorrect Word: 'qencil'\n",
            "Correct Word: 'pencil'\n",
            "Error Type: Visual similarity confusion\n",
            "---\n",
            "Incorrect Word: 'lmportant'\n",
            "Correct Word: 'important'\n",
            "Error Type: Visual similarity confusion\n",
            "---\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aFORPhHBmnyh"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyPvAQwzEyb1Vk75wfPnvUjS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}